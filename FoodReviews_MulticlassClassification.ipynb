{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98000/98000 [==============================] - 6s 64us/step - loss: 1.7119 - acc: 0.6389\n",
      "Epoch 2/5\n",
      "98000/98000 [==============================] - 6s 58us/step - loss: 1.5369 - acc: 0.6406\n",
      "Epoch 3/5\n",
      "98000/98000 [==============================] - 6s 59us/step - loss: 1.5356 - acc: 0.6406\n",
      "Epoch 4/5\n",
      "98000/98000 [==============================] - 6s 59us/step - loss: 1.5344 - acc: 0.6406\n",
      "Epoch 5/5\n",
      "98000/98000 [==============================] - 6s 59us/step - loss: 1.5334 - acc: 0.6406\n",
      "2000/2000 [==============================] - 0s 166us/step\n",
      "Model metrics names: ['loss', 'acc']\n",
      "Test score: [1.5492809972763062, 0.6275]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "An attempt to analyse food reviews with a simple Neural Network.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "\"\"\"\n",
    "The reviews is a rather big file, \n",
    "so it might be convenient to take only part of it\n",
    "according to computer performance and immediate task.\n",
    "GEFORCE RTX 2000 series takes a couple of minutes on following parameters. \n",
    "But on a laptop calculation might take up to 20 min, so please adjust, if necessary.\n",
    "\"\"\"\n",
    "\n",
    "DATA_SET_SIZE = 100000\n",
    "TEST_SIZE = 2000\n",
    "WORD_INDEX_SIZE = 10000\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Get the data from the file on computer (need to be downloaded), \n",
    "    take relevant columns and rows according to the DATA_SET_SIZE.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load data, take the size to be fed to the model and make a word index dictionary\n",
    "    data = pd.read_csv('Reviews.csv')\n",
    "    data = data.loc[:, ['Score', 'Text']]\n",
    "    data = shuffle(data)\n",
    "    data = data.iloc[:DATA_SET_SIZE, :]\n",
    "    word_index = get_word_index(WORD_INDEX_SIZE) \n",
    "    \n",
    "    # break dataset on train and test data\n",
    "    test = data.iloc[:TEST_SIZE, :]\n",
    "    data = data.iloc[TEST_SIZE:, :]\n",
    "    \n",
    "    # prepare train and test data and labels for the model\n",
    "    test_data = test['Text']\n",
    "    test_data_seq = get_sequences(test_data)\n",
    "    X_test = encode_review(test_data_seq)\n",
    "\n",
    "    test_labels = test['Score']\n",
    "    test_labels = get_labels(test_labels)\n",
    "    one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "    train_data = data['Text']\n",
    "    train_data_seq = get_sequences(train_data)\n",
    "    X_train = encode_review(train_data_seq)\n",
    "\n",
    "    train_labels = data['Score']\n",
    "    train_labels = get_labels(train_labels)\n",
    "    one_hot_train_labels = to_one_hot(train_labels)\n",
    "\n",
    "    # get and print the model score\n",
    "    model = get_model()\n",
    "    test_score = model.evaluate(X_test, one_hot_test_labels)\n",
    "    print(\"Model metrics names: {}\".format(model.metrics_names))\n",
    "    print(\"Test score: {}\".format(test_score))\n",
    "\n",
    "def clean_review(review):\n",
    "    \"\"\"\n",
    "    Implement simple data review cleaning with dropping HTML tags\n",
    "    and punctuation. Clean words are put into a list.\n",
    "    \n",
    "    Example: \n",
    "    \"Product recieved is as adrertised. <br />\" => \n",
    "    ['product', 'recieved', 'is', 'as', 'advertised']\n",
    "    \"\"\"\n",
    "    \n",
    "    cl_review = []\n",
    "    review = re.sub(\"<.*?>\", \" \", review)\n",
    "    review = ''.join([i for i in review if not i.isdigit()])\n",
    "    review = review.split()\n",
    "    for word in review:\n",
    "        word = word.lower()\n",
    "        word = word.strip(string.punctuation)\n",
    "        if len(word) > 0:\n",
    "            cl_review.append(word)\n",
    "    return cl_review\n",
    "\n",
    "def get_word_index(num_most_common=1000):\n",
    "    \"\"\"\n",
    "    Count words in the word list and make a dictionary with words as keys.\n",
    "    Return the dictionary.\n",
    "    \n",
    "    Example:\n",
    "    ['product', 'recieved', 'is', 'as', 'advertised', ...] =>\n",
    "    dict({\"product\": 10, \"recieved\": 5, \"is\": 20, \"as\": 12, \"advertised\": 3, ...})\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_words = []\n",
    "    for i, review in enumerate(data['Text']):\n",
    "        review = clean_review(review)\n",
    "        for word in review:\n",
    "            list_of_words.append(word)\n",
    "\n",
    "    word_fq = Counter(list_of_words).most_common(num_most_common)\n",
    "\n",
    "    word_index = {}\n",
    "    for i, (w, c) in enumerate(word_fq):\n",
    "        word_index[w] = i\n",
    "    return word_index\n",
    "    \n",
    "def get_sequences(data):\n",
    "    \"\"\"\n",
    "    Encode words that constitute a review with an order number from the word_index dictionary.\n",
    "    \n",
    "    Example:\n",
    "    ['product', 'recieved', 'is', 'as', 'advertised'] =>\n",
    "    [43, 12, 66, 102, 4]\n",
    "    \"\"\"\n",
    "    \n",
    "    sequences = []\n",
    "    for i, rev in data.iteritems():\n",
    "        rev = clean_review(rev)\n",
    "        review = []\n",
    "        for word in rev:\n",
    "            try:\n",
    "                word_index[word]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            else:\n",
    "                review.append(word_index[word])\n",
    "        sequences.append(review)\n",
    "    return np.array(sequences)\n",
    "    \n",
    "def encode_review(sequences, dimension=WORD_INDEX_SIZE):\n",
    "    \"\"\"\n",
    "    Make a sparse matrix to encode a review with 0 and 1.\n",
    "    \n",
    "    Example:\n",
    "    [43, 12, 66, 102, 4] =>\n",
    "    [0, 0, 0, .... 1, 0, 0, ... 1, 0, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    result = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        result[i, sequence] = 1.\n",
    "    return result\n",
    "\n",
    "def get_labels(data):\n",
    "    \"\"\"\n",
    "    Take labels 1 - 5 from dataset. (1 is a negative, 5 is a positive review)\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in data.iteritems():\n",
    "        labels.append(label-1)\n",
    "    return np.array(labels)\n",
    "\n",
    "def to_one_hot(labels, dimension=5):\n",
    "    \"\"\"\n",
    "    Sparse labels.\n",
    "    \n",
    "    Example:\n",
    "    1\n",
    "    3\n",
    "    =>\n",
    "    1, 0, 0, 0, 0\n",
    "    0, 0, 1, 0, 0\n",
    "    \"\"\"\n",
    "    \n",
    "    result = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        result[i, label] = 1.\n",
    "    return result\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    Build and fit a Keras Sequential model with 3 layers \n",
    "    and softmax activation as advised for multiclass classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(8, kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.001), \n",
    "                           activation='relu', input_shape=(WORD_INDEX_SIZE, )))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.001), \n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "    model.fit(X_train, one_hot_train_labels, epochs=5, batch_size=125, verbose=1)\n",
    "    return model\n",
    "\n",
    "main()\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
